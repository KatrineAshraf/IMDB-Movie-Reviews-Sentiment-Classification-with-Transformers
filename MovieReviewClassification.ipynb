{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE CONDA ENVIRONMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda env create -f env.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda activate sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv, get_dummies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, TrainingArguments, Trainer, TrainerCallback\n",
    "from torch import cuda, device, float16\n",
    "from torch.utils.data import Dataset\n",
    "import re\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import wandb\n",
    "from datasets import DatasetDict, Dataset\n",
    "import os\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INSTALLING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n",
      "License(s): other\n",
      "Downloading imdb-dataset-of-50k-movie-reviews.zip to d:\\FCDS\\Bert-Roberta-RNN-Movie-Reviews-Sentiment-1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/25.7M [00:00<?, ?B/s]\n",
      "  4%|▍         | 1.00M/25.7M [00:18<07:25, 58.2kB/s]\n",
      "  4%|▍         | 1.00M/25.7M [00:30<07:25, 58.2kB/s]\n",
      "  8%|▊         | 2.00M/25.7M [00:32<06:12, 66.7kB/s]\n",
      " 12%|█▏        | 3.00M/25.7M [00:48<06:05, 65.2kB/s]\n",
      " 12%|█▏        | 3.00M/25.7M [01:00<06:05, 65.2kB/s]\n",
      " 16%|█▌        | 4.00M/25.7M [01:14<07:11, 52.7kB/s]\n",
      " 16%|█▌        | 4.00M/25.7M [01:30<07:11, 52.7kB/s]\n",
      " 19%|█▉        | 5.00M/25.7M [02:26<13:23, 27.0kB/s]\n",
      " 19%|█▉        | 5.00M/25.7M [02:40<13:23, 27.0kB/s]\n",
      " 23%|██▎       | 6.00M/25.7M [04:08<19:49, 17.4kB/s]\n",
      " 23%|██▎       | 6.00M/25.7M [04:20<19:49, 17.4kB/s]\n",
      " 27%|██▋       | 7.00M/25.7M [05:14<19:23, 16.9kB/s]\n",
      " 27%|██▋       | 7.00M/25.7M [05:30<19:23, 16.9kB/s]\n",
      " 31%|███       | 8.00M/25.7M [06:17<18:26, 16.8kB/s]\n",
      " 31%|███       | 8.00M/25.7M [06:30<18:26, 16.8kB/s]\n",
      " 35%|███▌      | 9.00M/25.7M [06:39<13:52, 21.1kB/s]\n",
      " 35%|███▌      | 9.00M/25.7M [06:50<13:52, 21.1kB/s]\n",
      " 39%|███▉      | 10.0M/25.7M [07:02<10:52, 25.3kB/s]\n",
      " 39%|███▉      | 10.0M/25.7M [07:20<10:52, 25.3kB/s]\n",
      " 43%|████▎     | 11.0M/25.7M [07:30<09:10, 28.0kB/s]\n",
      " 43%|████▎     | 11.0M/25.7M [07:50<09:10, 28.0kB/s]\n",
      " 47%|████▋     | 12.0M/25.7M [07:54<07:33, 31.7kB/s]\n",
      " 47%|████▋     | 12.0M/25.7M [08:10<07:33, 31.7kB/s]\n",
      " 51%|█████     | 13.0M/25.7M [08:14<06:10, 36.0kB/s]\n",
      " 54%|█████▍    | 14.0M/25.7M [08:30<04:54, 41.7kB/s]\n",
      " 54%|█████▍    | 14.0M/25.7M [08:40<04:54, 41.7kB/s]\n",
      " 58%|█████▊    | 15.0M/25.7M [08:47<04:02, 46.2kB/s]\n",
      " 58%|█████▊    | 15.0M/25.7M [09:00<04:02, 46.2kB/s]\n",
      " 62%|██████▏   | 16.0M/25.7M [09:03<03:21, 50.7kB/s]\n",
      " 66%|██████▌   | 17.0M/25.7M [09:16<02:40, 56.8kB/s]\n",
      " 66%|██████▌   | 17.0M/25.7M [09:30<02:40, 56.8kB/s]\n",
      " 70%|███████   | 18.0M/25.7M [09:34<02:20, 57.5kB/s]\n",
      " 74%|███████▍  | 19.0M/25.7M [09:49<01:57, 60.0kB/s]\n",
      " 74%|███████▍  | 19.0M/25.7M [10:00<01:57, 60.0kB/s]\n",
      " 78%|███████▊  | 20.0M/25.7M [10:02<01:31, 65.7kB/s]\n",
      " 82%|████████▏ | 21.0M/25.7M [10:13<01:08, 71.8kB/s]\n",
      " 86%|████████▌ | 22.0M/25.7M [10:30<00:56, 69.3kB/s]\n",
      " 86%|████████▌ | 22.0M/25.7M [10:40<00:56, 69.3kB/s]\n",
      " 89%|████████▉ | 23.0M/25.7M [10:41<00:37, 75.5kB/s]\n",
      " 93%|█████████▎| 24.0M/25.7M [11:00<00:26, 67.7kB/s]\n",
      " 93%|█████████▎| 24.0M/25.7M [11:10<00:26, 67.7kB/s]\n",
      " 97%|█████████▋| 25.0M/25.7M [11:17<00:11, 65.9kB/s]\n",
      " 97%|█████████▋| 25.0M/25.7M [11:30<00:11, 65.9kB/s]\n",
      "100%|██████████| 25.7M/25.7M [11:30<00:00, 63.0kB/s]\n",
      "100%|██████████| 25.7M/25.7M [11:30<00:00, 39.0kB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d lakshmi25npathi/imdb-dataset-of-50k-movie-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ZipFile('imdb-dataset-of-50k-movie-reviews.zip', 'r') as extractor:\n",
    "    extractor.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove('imdb-dataset-of-50k-movie-reviews.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## READING & ADJUSTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  One of the other reviewers has mentioned that ...          1\n",
       "1  A wonderful little production. <br /><br />The...          1\n",
       "2  I thought this was a wonderful way to spend ti...          1\n",
       "3  Basically there's a family where a little boy ...          0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = read_csv(\"IMDB Dataset.csv\")\n",
    "data['sentiment'] = get_dummies(data['sentiment'],drop_first=True, dtype=int)['positive'] \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEANR = re.compile('<.*?>')\n",
    "for i, r in data.iterrows():\n",
    "    data.at[i, 'review'] = re.sub(CLEANR,\"\",r['review'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPLITTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, train_size = 0.7, shuffle = True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data split %\n",
      "Train: 70%\tTest: 30%\n"
     ]
    }
   ],
   "source": [
    "print(\"Original data split %\")\n",
    "print(f\"Train: {int((len(train)/len(data))*100)}%\", end=\"\\t\")\n",
    "print(f\"Test: {int((len(test)/len(data))*100)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENERATING HUGGING FACE DATASET FORMAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['review', 'sentiment'],\n",
      "        num_rows: 35000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['review', 'sentiment'],\n",
      "        num_rows: 15000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "train = Dataset.from_pandas(train).remove_columns([\"__index_level_0__\"])\n",
    "test = Dataset.from_pandas(test).remove_columns([\"__index_level_0__\"])\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    'train': train,\n",
    "    'test': test,\n",
    "})\n",
    "data = dataset.rename_column('sentiment', 'label')\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT SEQUENCE CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOKENIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08a999768cd24d5fa30327f2b887c572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/35000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f747c2ee196a4edbb38bfc072727a644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"review\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_dataset = data.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL INITIALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"google-bert/bert-base-uncased\", num_labels=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is moved to gpu\n"
     ]
    }
   ],
   "source": [
    "device_0 = device('cuda' if cuda.is_available else 'cpu')\n",
    "if device_0.type == 'cuda':\n",
    "    model.to(device_0)\n",
    "    print('model is moved to gpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomWandbCallback(TrainerCallback):\n",
    "    def __init__(self, wandb):\n",
    "        self.wandb = wandb\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs is not None:\n",
    "            epoch = logs.get(\"epoch\", state.epoch)\n",
    "            for key, value in logs.items():\n",
    "                if \"loss\" in key or \"accuracy\" in key:\n",
    "                    self.wandb.log({f\"{key}\": value, \"epoch\": epoch})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINER & TRAINING ARGUMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    report_to='wandb',\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    num_train_epochs=7,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"].shuffle(seed=42).select(range(1000)),\n",
    "    eval_dataset=tokenized_dataset[\"test\"].select(range(300)),\n",
    "    callbacks=[CustomWandbCallback(wandb)],\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## W&B SET UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\Katie\\_netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=os.environ.get('WANDB_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7c5e12a35974345b2ef58cd061b7647",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011288888888884685, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\FCDS\\Movie Reviews Sentiment Classification with Transformers\\wandb\\run-20240716_234344-xnzq8abs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/SoloWork/Movie%20Review%20Sentiment%20Classification%20with%20Tranformers/runs/xnzq8abs' target=\"_blank\">bert_run</a></strong> to <a href='https://wandb.ai/SoloWork/Movie%20Review%20Sentiment%20Classification%20with%20Tranformers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/SoloWork/Movie%20Review%20Sentiment%20Classification%20with%20Tranformers' target=\"_blank\">https://wandb.ai/SoloWork/Movie%20Review%20Sentiment%20Classification%20with%20Tranformers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/SoloWork/Movie%20Review%20Sentiment%20Classification%20with%20Tranformers/runs/xnzq8abs' target=\"_blank\">https://wandb.ai/SoloWork/Movie%20Review%20Sentiment%20Classification%20with%20Tranformers/runs/xnzq8abs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project='Movie Review Sentiment Classification with Tranformers', name='bert_run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/SoloWork/Movie%20Review%20Sentiment%20Classification%20with%20Tranformers/runs/xnzq8abs?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x12ee646adf0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01c59a23981c418ab6e7ac8809ac0452",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4226, 'grad_norm': 23.50316619873047, 'learning_rate': 4.2857142857142856e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "922be5aee3194b40a775622ba17e815c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.21635307371616364, 'eval_accuracy': 0.92, 'eval_runtime': 15.9264, 'eval_samples_per_second': 18.837, 'eval_steps_per_second': 2.386, 'epoch': 1.0}\n",
      "{'loss': 0.2245, 'grad_norm': 0.18228253722190857, 'learning_rate': 3.571428571428572e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b3767afc24943a4a7cc19801685c2e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.35450059175491333, 'eval_accuracy': 0.9066666666666666, 'eval_runtime': 15.6923, 'eval_samples_per_second': 19.118, 'eval_steps_per_second': 2.422, 'epoch': 2.0}\n",
      "{'loss': 0.0957, 'grad_norm': 99.09716033935547, 'learning_rate': 2.857142857142857e-05, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d0ecba29b91442b9d535f42e1e12bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5825324654579163, 'eval_accuracy': 0.89, 'eval_runtime': 15.6292, 'eval_samples_per_second': 19.195, 'eval_steps_per_second': 2.431, 'epoch': 3.0}\n",
      "{'loss': 0.0231, 'grad_norm': 0.012049528770148754, 'learning_rate': 2.1428571428571428e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1487b12982c049219b48f1a81cd7886e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5057306289672852, 'eval_accuracy': 0.9133333333333333, 'eval_runtime': 16.2758, 'eval_samples_per_second': 18.432, 'eval_steps_per_second': 2.335, 'epoch': 4.0}\n",
      "{'loss': 0.008, 'grad_norm': 0.0043056015856564045, 'learning_rate': 1.4285714285714285e-05, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aca036282894af9b2d37cd91a106604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5529717206954956, 'eval_accuracy': 0.9233333333333333, 'eval_runtime': 15.7455, 'eval_samples_per_second': 19.053, 'eval_steps_per_second': 2.413, 'epoch': 5.0}\n",
      "{'loss': 0.0001, 'grad_norm': 0.002354174619540572, 'learning_rate': 7.142857142857143e-06, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8a31b08a8264886bc09658ab6fbdccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5680630803108215, 'eval_accuracy': 0.9233333333333333, 'eval_runtime': 15.9324, 'eval_samples_per_second': 18.83, 'eval_steps_per_second': 2.385, 'epoch': 6.0}\n",
      "{'loss': 0.0001, 'grad_norm': 0.002003719098865986, 'learning_rate': 0.0, 'epoch': 7.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28c8b2962ab243afad0b4f5f64956c8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5623147487640381, 'eval_accuracy': 0.9233333333333333, 'eval_runtime': 15.9103, 'eval_samples_per_second': 18.856, 'eval_steps_per_second': 2.388, 'epoch': 7.0}\n",
      "{'train_runtime': 1084.5606, 'train_samples_per_second': 6.454, 'train_steps_per_second': 0.807, 'train_loss': 0.11058723449281284, 'epoch': 7.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=875, training_loss=0.11058723449281284, metrics={'train_runtime': 1084.5606, 'train_samples_per_second': 6.454, 'train_steps_per_second': 0.807, 'total_flos': 1841777387520000.0, 'train_loss': 0.11058723449281284, 'epoch': 7.0})"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Control-C detected -- Run data was not synced\n"
     ]
    }
   ],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DISTIL-BERT SEQUENCE CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOKENIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7875cc7ced0749a8b08ea840d864b6e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/35000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53e7af747183465dbaead3b62b86e369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"review\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_dataset = data.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL INITIALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert/distilbert-base-uncased\", num_labels=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is moved to gpu\n"
     ]
    }
   ],
   "source": [
    "device_1 = device('cuda' if cuda.is_available else 'cpu')\n",
    "if device_1.type == 'cuda':\n",
    "    model.to(device_1)\n",
    "    print('model is moved to gpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomWandbCallback(TrainerCallback):\n",
    "    def __init__(self, wandb):\n",
    "        self.wandb = wandb\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs is not None:\n",
    "            epoch = logs.get(\"epoch\", state.epoch)\n",
    "            for key, value in logs.items():\n",
    "                if \"loss\" in key or \"accuracy\" in key:\n",
    "                    self.wandb.log({f\"{key}\": value, \"epoch\": epoch})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINER & TRAINING ARGUMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    report_to='wandb',\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    num_train_epochs=7\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"].shuffle(seed=42).select(range(1000)),\n",
    "    eval_dataset=tokenized_dataset[\"test\"].select(range(300)),\n",
    "    callbacks=[CustomWandbCallback(wandb)],\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## W&B SET UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkatherineashraf\u001b[0m (\u001b[33mSoloWork\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\Katie\\_netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.login(key=os.environ.get('WANDB_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "597f372b75294156aac6f10d603477c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011111111111111112, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\FCDS\\Movie Reviews Sentiment Classification with Transformers\\wandb\\run-20240716_204358-9xsrv4sd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/SoloWork/Movie%20Review%20Sentiment%20Classification%20with%20Tranformers/runs/9xsrv4sd' target=\"_blank\">distil-bert_run</a></strong> to <a href='https://wandb.ai/SoloWork/Movie%20Review%20Sentiment%20Classification%20with%20Tranformers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/SoloWork/Movie%20Review%20Sentiment%20Classification%20with%20Tranformers' target=\"_blank\">https://wandb.ai/SoloWork/Movie%20Review%20Sentiment%20Classification%20with%20Tranformers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/SoloWork/Movie%20Review%20Sentiment%20Classification%20with%20Tranformers/runs/9xsrv4sd' target=\"_blank\">https://wandb.ai/SoloWork/Movie%20Review%20Sentiment%20Classification%20with%20Tranformers/runs/9xsrv4sd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project='Movie Review Sentiment Classification with Tranformers', name='distil-bert_run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/SoloWork/Movie%20Review%20Sentiment%20Classification%20with%20Tranformers/runs/9xsrv4sd?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x12d95594220>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d327eb7d62248f8b8436638a7601476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4628, 'grad_norm': 19.079669952392578, 'learning_rate': 4.2857142857142856e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5305879e9b244598afd93d3d21a5b450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6143785715103149, 'eval_accuracy': 0.74, 'eval_runtime': 9.2209, 'eval_samples_per_second': 32.535, 'eval_steps_per_second': 4.121, 'epoch': 1.0}\n",
      "{'loss': 0.2926, 'grad_norm': 4.9159440994262695, 'learning_rate': 3.571428571428572e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "268bd70ad1f44845ba17e8d8eb21425d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7516472339630127, 'eval_accuracy': 0.7833333333333333, 'eval_runtime': 8.9563, 'eval_samples_per_second': 33.496, 'eval_steps_per_second': 4.243, 'epoch': 2.0}\n",
      "{'loss': 0.1119, 'grad_norm': 0.12082237750291824, 'learning_rate': 2.857142857142857e-05, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0ab3a1bab754f01b6e27bfee4f0d828",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.41157156229019165, 'eval_accuracy': 0.91, 'eval_runtime': 8.9448, 'eval_samples_per_second': 33.539, 'eval_steps_per_second': 4.248, 'epoch': 3.0}\n",
      "{'loss': 0.0346, 'grad_norm': 0.009427830576896667, 'learning_rate': 2.1428571428571428e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbe25d6248d24a829649d550eceaccda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5523303151130676, 'eval_accuracy': 0.8833333333333333, 'eval_runtime': 9.3896, 'eval_samples_per_second': 31.95, 'eval_steps_per_second': 4.047, 'epoch': 4.0}\n",
      "{'loss': 0.0094, 'grad_norm': 0.04642750695347786, 'learning_rate': 1.4285714285714285e-05, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92800c50f36641cd8a71e9e4c5b161e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5800144076347351, 'eval_accuracy': 0.8933333333333333, 'eval_runtime': 9.5684, 'eval_samples_per_second': 31.353, 'eval_steps_per_second': 3.971, 'epoch': 5.0}\n",
      "{'loss': 0.0029, 'grad_norm': 0.005240229889750481, 'learning_rate': 7.142857142857143e-06, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f046183880e043a49af863037a9e7a22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6185078024864197, 'eval_accuracy': 0.89, 'eval_runtime': 9.5685, 'eval_samples_per_second': 31.353, 'eval_steps_per_second': 3.971, 'epoch': 6.0}\n",
      "{'loss': 0.001, 'grad_norm': 0.00587252713739872, 'learning_rate': 0.0, 'epoch': 7.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a08e37bbd654626acd5ac57fde1daa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6027518510818481, 'eval_accuracy': 0.8866666666666667, 'eval_runtime': 9.0077, 'eval_samples_per_second': 33.305, 'eval_steps_per_second': 4.219, 'epoch': 7.0}\n",
      "{'train_runtime': 569.0017, 'train_samples_per_second': 12.302, 'train_steps_per_second': 1.538, 'train_loss': 0.13075893207958766, 'epoch': 7.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=875, training_loss=0.13075893207958766, metrics={'train_runtime': 569.0017, 'train_samples_per_second': 12.302, 'train_steps_per_second': 1.538, 'total_flos': 927271790592000.0, 'train_loss': 0.13075893207958766, 'epoch': 7.0})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd4e9bce57fb40ab8216d4e31f4cf8e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▃▃▃▅▅▅▆▆▆▇▇▇████</td></tr><tr><td>eval/accuracy</td><td>▁▃█▇▇▇▇</td></tr><tr><td>eval/loss</td><td>▅█▁▄▄▅▅</td></tr><tr><td>eval/runtime</td><td>▄▁▁▆██▂</td></tr><tr><td>eval/samples_per_second</td><td>▅██▃▁▁▇</td></tr><tr><td>eval/steps_per_second</td><td>▅██▃▁▁▇</td></tr><tr><td>eval_accuracy</td><td>▁▃█▇▇▇▇</td></tr><tr><td>eval_loss</td><td>▅█▁▄▄▅▅</td></tr><tr><td>loss</td><td>█▅▃▂▁▁▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▅▅▆▆▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███████</td></tr><tr><td>train/grad_norm</td><td>█▃▁▁▁▁▁</td></tr><tr><td>train/learning_rate</td><td>█▇▆▅▃▂▁</td></tr><tr><td>train/loss</td><td>█▅▃▂▁▁▁</td></tr><tr><td>train_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>7.0</td></tr><tr><td>eval/accuracy</td><td>0.88667</td></tr><tr><td>eval/loss</td><td>0.60275</td></tr><tr><td>eval/runtime</td><td>9.0077</td></tr><tr><td>eval/samples_per_second</td><td>33.305</td></tr><tr><td>eval/steps_per_second</td><td>4.219</td></tr><tr><td>eval_accuracy</td><td>0.88667</td></tr><tr><td>eval_loss</td><td>0.60275</td></tr><tr><td>loss</td><td>0.001</td></tr><tr><td>total_flos</td><td>927271790592000.0</td></tr><tr><td>train/epoch</td><td>7.0</td></tr><tr><td>train/global_step</td><td>875</td></tr><tr><td>train/grad_norm</td><td>0.00587</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.001</td></tr><tr><td>train_loss</td><td>0.13076</td></tr><tr><td>train_runtime</td><td>569.0017</td></tr><tr><td>train_samples_per_second</td><td>12.302</td></tr><tr><td>train_steps_per_second</td><td>1.538</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">distil-bert_run</strong> at: <a href='https://wandb.ai/SoloWork/Movie%20Review%20Sentiment%20Classification%20with%20Tranformers/runs/9xsrv4sd' target=\"_blank\">https://wandb.ai/SoloWork/Movie%20Review%20Sentiment%20Classification%20with%20Tranformers/runs/9xsrv4sd</a><br/> View project at: <a href='https://wandb.ai/SoloWork/Movie%20Review%20Sentiment%20Classification%20with%20Tranformers' target=\"_blank\">https://wandb.ai/SoloWork/Movie%20Review%20Sentiment%20Classification%20with%20Tranformers</a><br/>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240716_204358-9xsrv4sd\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROBERTA SEQUENCE CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOKENIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b6568c547174309b33eedd955496708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c2f0b70bc414acc93b087842b55fb9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "337fea07360d435b8d4110c51fe445ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b86c4831f85e4e13b13a933684913bf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cd34bbab26d4d0388d70da075991093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/35000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff16149f35fe4141bdee6b4260f777c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"review\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_dataset = data.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL INITIALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "070634e5f4004712ac46437f935a08a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7089ab5e13b40da800efa2a49c35296",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is moved to gpu\n"
     ]
    }
   ],
   "source": [
    "device_1 = device('cuda' if cuda.is_available else 'cpu')\n",
    "if device_1.type == 'cuda':\n",
    "    model.to(device_1)\n",
    "    print('model is moved to gpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomWandbCallback(TrainerCallback):\n",
    "    def __init__(self, wandb):\n",
    "        self.wandb = wandb\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs is not None:\n",
    "            epoch = logs.get(\"epoch\", state.epoch)\n",
    "            for key, value in logs.items():\n",
    "                if \"loss\" in key or \"accuracy\" in key:\n",
    "                    self.wandb.log({f\"{key}\": value, \"epoch\": epoch})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINER & TRAINING ARGUMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    report_to='wandb',\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    num_train_epochs=7\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"].shuffle(seed=42).select(range(1000)),\n",
    "    eval_dataset=tokenized_dataset[\"test\"].select(range(300)),\n",
    "    callbacks=[CustomWandbCallback(wandb)],\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## W&B SET UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\Katie\\_netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=os.environ.get('WANDB_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\FCDS\\Movie Reviews Sentiment Classification with Transformers\\wandb\\run-20240716_220952-9w39en5x</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/SoloWork/Movie%20Review%20Sentiment%20Classification%20with%20Tranformers/runs/9w39en5x' target=\"_blank\">roberta_run</a></strong> to <a href='https://wandb.ai/SoloWork/Movie%20Review%20Sentiment%20Classification%20with%20Tranformers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/SoloWork/Movie%20Review%20Sentiment%20Classification%20with%20Tranformers' target=\"_blank\">https://wandb.ai/SoloWork/Movie%20Review%20Sentiment%20Classification%20with%20Tranformers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/SoloWork/Movie%20Review%20Sentiment%20Classification%20with%20Tranformers/runs/9w39en5x' target=\"_blank\">https://wandb.ai/SoloWork/Movie%20Review%20Sentiment%20Classification%20with%20Tranformers/runs/9w39en5x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project='Movie Review Sentiment Classification with Tranformers', name='roberta_run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/SoloWork/Movie%20Review%20Sentiment%20Classification%20with%20Tranformers/runs/9w39en5x?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x12d950872e0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a36f419053b146939b481b1133e13ccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5, 'grad_norm': 7.648731231689453, 'learning_rate': 4.2857142857142856e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecccbb949a5349c2a135cabdcbb2b418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.230277881026268, 'eval_accuracy': 0.9266666666666666, 'eval_runtime': 62.0393, 'eval_samples_per_second': 4.836, 'eval_steps_per_second': 0.613, 'epoch': 1.0}\n",
      "{'loss': 0.311, 'grad_norm': 0.1672140508890152, 'learning_rate': 3.571428571428572e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2edfa257fc664715ae042d2b6e5862f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.501458466053009, 'eval_accuracy': 0.89, 'eval_runtime': 62.5536, 'eval_samples_per_second': 4.796, 'eval_steps_per_second': 0.607, 'epoch': 2.0}\n",
      "{'loss': 0.215, 'grad_norm': 6.544699668884277, 'learning_rate': 2.857142857142857e-05, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baeb82b0f41149d2ac13bab582219bf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4504135549068451, 'eval_accuracy': 0.9066666666666666, 'eval_runtime': 63.9084, 'eval_samples_per_second': 4.694, 'eval_steps_per_second': 0.595, 'epoch': 3.0}\n",
      "{'loss': 0.1342, 'grad_norm': 37.261417388916016, 'learning_rate': 2.1428571428571428e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "792a87ffe9b04035a96f0a3543ce9cdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5497056841850281, 'eval_accuracy': 0.9033333333333333, 'eval_runtime': 62.3494, 'eval_samples_per_second': 4.812, 'eval_steps_per_second': 0.609, 'epoch': 4.0}\n",
      "{'loss': 0.0536, 'grad_norm': 0.10636503994464874, 'learning_rate': 1.4285714285714285e-05, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bb072c2cd2b42858c611842337e45ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.44834575057029724, 'eval_accuracy': 0.9133333333333333, 'eval_runtime': 61.5837, 'eval_samples_per_second': 4.871, 'eval_steps_per_second': 0.617, 'epoch': 5.0}\n",
      "{'loss': 0.0325, 'grad_norm': 0.025958357378840446, 'learning_rate': 7.142857142857143e-06, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "677cb0abd3f14da29d987169c0f31bd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.43520569801330566, 'eval_accuracy': 0.93, 'eval_runtime': 67.1405, 'eval_samples_per_second': 4.468, 'eval_steps_per_second': 0.566, 'epoch': 6.0}\n",
      "{'loss': 0.021, 'grad_norm': 0.02783527784049511, 'learning_rate': 0.0, 'epoch': 7.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10e7678a74ea4afda07f1d3518bc3136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.42528367042541504, 'eval_accuracy': 0.9266666666666666, 'eval_runtime': 67.3379, 'eval_samples_per_second': 4.455, 'eval_steps_per_second': 0.564, 'epoch': 7.0}\n",
      "{'train_runtime': 4336.9993, 'train_samples_per_second': 1.614, 'train_steps_per_second': 0.202, 'train_loss': 0.18105824170793805, 'epoch': 7.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=875, training_loss=0.18105824170793805, metrics={'train_runtime': 4336.9993, 'train_samples_per_second': 1.614, 'train_steps_per_second': 0.202, 'total_flos': 1841777387520000.0, 'train_loss': 0.18105824170793805, 'epoch': 7.0})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "769870b03ad54d538219f41c4721d5c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 5.9%             "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▃▃▃▅▅▅▆▆▆▇▇▇████</td></tr><tr><td>eval/accuracy</td><td>▇▁▄▃▅█▇</td></tr><tr><td>eval/loss</td><td>▁▇▆█▆▅▅</td></tr><tr><td>eval/runtime</td><td>▂▂▄▂▁██</td></tr><tr><td>eval/samples_per_second</td><td>▇▇▅▇█▁▁</td></tr><tr><td>eval/steps_per_second</td><td>▇▇▅▇█▁▁</td></tr><tr><td>eval_accuracy</td><td>▇▁▄▃▅█▇</td></tr><tr><td>eval_loss</td><td>▁▇▆█▆▅▅</td></tr><tr><td>loss</td><td>█▅▄▃▁▁▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▅▅▆▆▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███████</td></tr><tr><td>train/grad_norm</td><td>▂▁▂█▁▁▁</td></tr><tr><td>train/learning_rate</td><td>█▇▆▅▃▂▁</td></tr><tr><td>train/loss</td><td>█▅▄▃▁▁▁</td></tr><tr><td>train_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>7.0</td></tr><tr><td>eval/accuracy</td><td>0.92667</td></tr><tr><td>eval/loss</td><td>0.42528</td></tr><tr><td>eval/runtime</td><td>67.3379</td></tr><tr><td>eval/samples_per_second</td><td>4.455</td></tr><tr><td>eval/steps_per_second</td><td>0.564</td></tr><tr><td>eval_accuracy</td><td>0.92667</td></tr><tr><td>eval_loss</td><td>0.42528</td></tr><tr><td>loss</td><td>0.021</td></tr><tr><td>total_flos</td><td>1841777387520000.0</td></tr><tr><td>train/epoch</td><td>7.0</td></tr><tr><td>train/global_step</td><td>875</td></tr><tr><td>train/grad_norm</td><td>0.02784</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.021</td></tr><tr><td>train_loss</td><td>0.18106</td></tr><tr><td>train_runtime</td><td>4336.9993</td></tr><tr><td>train_samples_per_second</td><td>1.614</td></tr><tr><td>train_steps_per_second</td><td>0.202</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">roberta_run</strong> at: <a href='https://wandb.ai/SoloWork/Movie%20Review%20Sentiment%20Classification%20with%20Tranformers/runs/9w39en5x' target=\"_blank\">https://wandb.ai/SoloWork/Movie%20Review%20Sentiment%20Classification%20with%20Tranformers/runs/9w39en5x</a><br/> View project at: <a href='https://wandb.ai/SoloWork/Movie%20Review%20Sentiment%20Classification%20with%20Tranformers' target=\"_blank\">https://wandb.ai/SoloWork/Movie%20Review%20Sentiment%20Classification%20with%20Tranformers</a><br/>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240716_220952-9w39en5x\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELECTRA SEQUENCE CLASSSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOKENIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1a76222a73c411293a82793b9c695ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d5bd9044b6343a885106ea5cafe5923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f06c88a8f2d24deeaf7d4a9e5c3e56e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dae1a38f8de9440fb88a91c840699d91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff984ffee49042538dede18f03ddd60e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/35000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a5210eaaffa43aea1862d95ea6ea7b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google/electra-small-discriminator\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"review\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_dataset = data.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL INITIALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c3974d674a54d048fdfbd2eec623ce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/54.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"google/electra-small-discriminator\", num_labels=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is moved to gpu\n"
     ]
    }
   ],
   "source": [
    "device_1 = device('cuda' if cuda.is_available else 'cpu')\n",
    "if device_1.type == 'cuda':\n",
    "    model.to(device_1)\n",
    "    print('model is moved to gpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomWandbCallback(TrainerCallback):\n",
    "    def __init__(self, wandb):\n",
    "        self.wandb = wandb\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs is not None:\n",
    "            epoch = logs.get(\"epoch\", state.epoch)\n",
    "            for key, value in logs.items():\n",
    "                if \"loss\" in key or \"accuracy\" in key:\n",
    "                    self.wandb.log({f\"{key}\": value, \"epoch\": epoch})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINER & TRAINING ARGUMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    report_to='wandb',\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    num_train_epochs=7\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"].shuffle(seed=42).select(range(1000)),\n",
    "    eval_dataset=tokenized_dataset[\"test\"].select(range(300)),\n",
    "    callbacks=[CustomWandbCallback(wandb)],\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## W&B SET UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\Katie\\_netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=os.environ.get('WANDB_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\FCDS\\Movie Reviews Sentiment Classification with Transformers\\wandb\\run-20240716_232326-gxwrzrok</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/SoloWork/Movie%20Review%20Sentiment%20Classification%20with%20Tranformers/runs/gxwrzrok' target=\"_blank\">electra_run</a></strong> to <a href='https://wandb.ai/SoloWork/Movie%20Review%20Sentiment%20Classification%20with%20Tranformers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/SoloWork/Movie%20Review%20Sentiment%20Classification%20with%20Tranformers' target=\"_blank\">https://wandb.ai/SoloWork/Movie%20Review%20Sentiment%20Classification%20with%20Tranformers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/SoloWork/Movie%20Review%20Sentiment%20Classification%20with%20Tranformers/runs/gxwrzrok' target=\"_blank\">https://wandb.ai/SoloWork/Movie%20Review%20Sentiment%20Classification%20with%20Tranformers/runs/gxwrzrok</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project='Movie Review Sentiment Classification with Tranformers', name='electra_run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/SoloWork/Movie%20Review%20Sentiment%20Classification%20with%20Tranformers/runs/gxwrzrok?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x12d95290b80>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "126d501b087a423a8faac90fce31a58d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6154, 'grad_norm': 5.137572765350342, 'learning_rate': 4.2857142857142856e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f6932580fb3464b9fa2473f3606b7d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.41971415281295776, 'eval_accuracy': 0.8866666666666667, 'eval_runtime': 2.5594, 'eval_samples_per_second': 117.213, 'eval_steps_per_second': 14.847, 'epoch': 1.0}\n",
      "{'loss': 0.3627, 'grad_norm': 8.133498191833496, 'learning_rate': 3.571428571428572e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99def27281b74aad9ca3b342492aee28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2593539357185364, 'eval_accuracy': 0.9033333333333333, 'eval_runtime': 2.5515, 'eval_samples_per_second': 117.579, 'eval_steps_per_second': 14.893, 'epoch': 2.0}\n",
      "{'loss': 0.1981, 'grad_norm': 92.19606018066406, 'learning_rate': 2.857142857142857e-05, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab7b3c6717974943845eb82e932eaccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3325931429862976, 'eval_accuracy': 0.9166666666666666, 'eval_runtime': 2.5493, 'eval_samples_per_second': 117.682, 'eval_steps_per_second': 14.906, 'epoch': 3.0}\n",
      "{'loss': 0.1307, 'grad_norm': 0.9414613842964172, 'learning_rate': 2.1428571428571428e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb55deb4e7fc4464834de1643016aae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.37201422452926636, 'eval_accuracy': 0.9, 'eval_runtime': 2.5714, 'eval_samples_per_second': 116.667, 'eval_steps_per_second': 14.778, 'epoch': 4.0}\n",
      "{'loss': 0.0793, 'grad_norm': 12.879191398620605, 'learning_rate': 1.4285714285714285e-05, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8594ee4b7f6d47be96b0d19aadffed63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.41390442848205566, 'eval_accuracy': 0.9033333333333333, 'eval_runtime': 2.7033, 'eval_samples_per_second': 110.976, 'eval_steps_per_second': 14.057, 'epoch': 5.0}\n",
      "{'loss': 0.0408, 'grad_norm': 0.08070999383926392, 'learning_rate': 7.142857142857143e-06, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4a64bd971aa4e01985f05e3941c0893",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4389466941356659, 'eval_accuracy': 0.91, 'eval_runtime': 2.5792, 'eval_samples_per_second': 116.317, 'eval_steps_per_second': 14.734, 'epoch': 6.0}\n",
      "{'loss': 0.036, 'grad_norm': 0.08362441509962082, 'learning_rate': 0.0, 'epoch': 7.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28cf217851b04744b2d2579895b017d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4470287561416626, 'eval_accuracy': 0.91, 'eval_runtime': 2.5628, 'eval_samples_per_second': 117.061, 'eval_steps_per_second': 14.828, 'epoch': 7.0}\n",
      "{'train_runtime': 179.1875, 'train_samples_per_second': 39.065, 'train_steps_per_second': 4.883, 'train_loss': 0.20898332105364117, 'epoch': 7.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=875, training_loss=0.20898332105364117, metrics={'train_runtime': 179.1875, 'train_samples_per_second': 39.065, 'train_steps_per_second': 4.883, 'total_flos': 205937485824000.0, 'train_loss': 0.20898332105364117, 'epoch': 7.0})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35750942e6c54afdb6cce28ca7f8fef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.031 MB of 0.047 MB uploaded (0.003 MB deduped)\\r'), FloatProgress(value=0.663057…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 5.8%             "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▃▃▃▅▅▅▆▆▆▇▇▇████</td></tr><tr><td>eval/accuracy</td><td>▁▅█▄▅▆▆</td></tr><tr><td>eval/loss</td><td>▇▁▄▅▇██</td></tr><tr><td>eval/runtime</td><td>▁▁▁▂█▂▂</td></tr><tr><td>eval/samples_per_second</td><td>███▇▁▇▇</td></tr><tr><td>eval/steps_per_second</td><td>███▇▁▇▇</td></tr><tr><td>eval_accuracy</td><td>▁▅█▄▅▆▆</td></tr><tr><td>eval_loss</td><td>▇▁▄▅▇██</td></tr><tr><td>loss</td><td>█▅▃▂▂▁▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▅▅▆▆▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███████</td></tr><tr><td>train/grad_norm</td><td>▁▂█▁▂▁▁</td></tr><tr><td>train/learning_rate</td><td>█▇▆▅▃▂▁</td></tr><tr><td>train/loss</td><td>█▅▃▂▂▁▁</td></tr><tr><td>train_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>7.0</td></tr><tr><td>eval/accuracy</td><td>0.91</td></tr><tr><td>eval/loss</td><td>0.44703</td></tr><tr><td>eval/runtime</td><td>2.5628</td></tr><tr><td>eval/samples_per_second</td><td>117.061</td></tr><tr><td>eval/steps_per_second</td><td>14.828</td></tr><tr><td>eval_accuracy</td><td>0.91</td></tr><tr><td>eval_loss</td><td>0.44703</td></tr><tr><td>loss</td><td>0.036</td></tr><tr><td>total_flos</td><td>205937485824000.0</td></tr><tr><td>train/epoch</td><td>7.0</td></tr><tr><td>train/global_step</td><td>875</td></tr><tr><td>train/grad_norm</td><td>0.08362</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.036</td></tr><tr><td>train_loss</td><td>0.20898</td></tr><tr><td>train_runtime</td><td>179.1875</td></tr><tr><td>train_samples_per_second</td><td>39.065</td></tr><tr><td>train_steps_per_second</td><td>4.883</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">electra_run</strong> at: <a href='https://wandb.ai/SoloWork/Movie%20Review%20Sentiment%20Classification%20with%20Tranformers/runs/gxwrzrok' target=\"_blank\">https://wandb.ai/SoloWork/Movie%20Review%20Sentiment%20Classification%20with%20Tranformers/runs/gxwrzrok</a><br/> View project at: <a href='https://wandb.ai/SoloWork/Movie%20Review%20Sentiment%20Classification%20with%20Tranformers' target=\"_blank\">https://wandb.ai/SoloWork/Movie%20Review%20Sentiment%20Classification%20with%20Tranformers</a><br/>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240716_232326-gxwrzrok\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: Bert\n",
      "Last Train Loss: 0.111\n",
      "Last Eval Loss: 0.562\n",
      "Loss Difference: 0.452\n",
      "\n",
      "Model Name: Distil-bert\n",
      "Last Train Loss: 0.131\n",
      "Last Eval Loss: 0.603\n",
      "Loss Difference: 0.472\n",
      "\n",
      "Model Name: Roberta\n",
      "Last Train Loss: 0.181\n",
      "Last Eval Loss: 0.425\n",
      "Loss Difference: 0.244\n",
      "\n",
      "Model Name: Electra\n",
      "Last Train Loss: 0.209\n",
      "Last Eval Loss: 0.447\n",
      "Loss Difference: 0.238\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_last_metrics(run, metric_name):\n",
    "    history = run.history(keys=[metric_name])\n",
    "    if not history.empty:\n",
    "        return history[metric_name].values[-1]\n",
    "    return None\n",
    "\n",
    "results = []\n",
    "\n",
    "api = wandb.Api()\n",
    "runs = api.runs(\"SoloWork/Movie Review Sentiment Classification with Tranformers\")\n",
    "\n",
    "for run in runs:\n",
    "    run_name = run.name\n",
    "    run_name = run_name.replace(\"_run\",\"\")\n",
    "    last_train_loss = get_last_metrics(run, \"train_loss\")\n",
    "    last_eval_loss = get_last_metrics(run, \"eval_loss\")\n",
    "    \n",
    "    if last_train_loss is not None and last_eval_loss is not None:\n",
    "        results.append({\n",
    "            \"run_name\": run_name.capitalize(),\n",
    "            \"last_train_loss\": last_train_loss,\n",
    "            \"last_eval_loss\": last_eval_loss,\n",
    "            \"loss_difference\": last_eval_loss - last_train_loss\n",
    "        })\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Model Name: {result['run_name']}\")\n",
    "    print(f\"Last Train Loss: {round(result['last_train_loss'],3)}\")\n",
    "    print(f\"Last Eval Loss: {round(result['last_eval_loss'],3)}\")\n",
    "    print(f\"Loss Difference: {round(result['loss_difference'],3)}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<ins>Summing up:</ins>**\n",
    "|| BERT | Distil-BERT | RoBERTa | Electra |\n",
    "| :-: | :-: | :-: | :-: | :-: |\n",
    "| **Training Loss** | 0.111 | 0.131 | 0.181 | 0.209 |\n",
    "| **Evaluation Loss** | 0.562 | 0.603 | <span style='color:cyan'> 0.425 </span> | 0.447 |\n",
    "| **Difference** | 0.452 | <span style='color:red'> 0.472 </span> | 0.244 | <span style='color:yellow'> 0.238 </span> |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although RoBERTa had the least evaluation loss, but Electra had the minimal difference between Training and Evaluation Loss, making it the least over-fit model among all four."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='Training_and_Evaluation_Loss_For_All_Transformers.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see that:\n",
    "The first to reach optimal points `(train_loss = val_loss)` is RoBERTa, followed by BERT, then Electra, however, DistilBert never reached it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MovieReviewSentiment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
